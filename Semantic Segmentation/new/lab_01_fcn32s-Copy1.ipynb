{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FCN_VGG16_32s  \n",
    "#### dataset: pascal voc 2012 segmentation(21分类)\n",
    "\n",
    "need:\n",
    "1. BilinearUpSampling.py \n",
    "2. [vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5](https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.regularizers import *\n",
    "import os\n",
    "from keras.models import Model\n",
    "from BilinearUpSampling import *\n",
    "\n",
    "def FCN_Vgg16_32s(input_shape=None, weight_decay=0., batch_momentum=0.9, batch_shape=None, classes=21):\n",
    "    if batch_shape:\n",
    "        img_input = Input(batch_shape=batch_shape)\n",
    "        image_size = batch_shape[1:3]\n",
    "    else:\n",
    "        img_input = Input(shape=input_shape)\n",
    "        image_size = input_shape[0:2]\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', kernel_regularizer=l2(weight_decay))(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    # Convolutional layers transfered from fully-connected layers\n",
    "    x = Conv2D(512, (7, 7), activation='relu', padding='same', name='fc1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(512, (1, 1), activation='relu', padding='same', name='fc2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #classifying layer\n",
    "    x = Conv2D(classes, (1, 1), kernel_initializer='he_normal', activation='linear', padding='valid', strides=(1, 1), kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "    x = BilinearUpSampling2D(size=(32, 32))(x)\n",
    "    x=(Activation('softmax'))(x)\n",
    "    model = Model(img_input, x)\n",
    "    weights_path='./vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 320, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 320, 320, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 320, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 160, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 160, 160, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 160, 160, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 80, 80, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 80, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 80, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 40, 40, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 40, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 40, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "fc1 (Conv2D)                 (None, 10, 10, 512)       12845568  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "fc2 (Conv2D)                 (None, 10, 10, 512)       262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 21)        10773     \n",
      "_________________________________________________________________\n",
      "bilinear_up_sampling2d_1 (Bi (None, 320, 320, 21)      0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 320, 320, 21)      0         \n",
      "=================================================================\n",
      "Total params: 27,833,685\n",
      "Trainable params: 27,833,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model=FCN_Vgg16_32s(input_shape=(320,320,3),classes=21)\n",
    "optimizer=optimizers.RMSprop(lr=1e-5)\n",
    "#可以自定义损失函数和metrics\n",
    "# loss_fn=softmax_sparse_crossentropy_ignoring_last_label\n",
    "# metrics=[sparse_accuracy_ignoring_last_label]\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model,to_file='fcn32s.jpg',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.处理数据，将mask转化为one_hot形式的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],\n",
    "            [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0],\n",
    "            [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128],\n",
    "            [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0],\n",
    "            [0, 192, 0], [128, 192, 0], [0, 64, 128]]\n",
    "cm2lbl = np.zeros(256 ** 3)  # 每个像素点有 0 ~ 255 的选择，RGB 三个通道\n",
    "for i, cm in enumerate(colormap):\n",
    "    cm2lbl[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = i  # 建立索引\n",
    "\n",
    "\n",
    "def image2label(im):\n",
    "    # 输入三维的mask图片，返回二维的矩阵，对每一个像素进行标记(320,320,3)->(320,320)\n",
    "    #如[0,0,0]标记为0,[128,0,0]标记为1\n",
    "    data = np.array(im, dtype='int32')\n",
    "    idx = (data[:, :, 0] * 256 + data[:, :, 1]) * 256 + data[:, :, 2]\n",
    "    return np.array(cm2lbl[idx], dtype='int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "base_path='/input0/pascal_2012_seg/'\n",
    "# val_base_path='/input0/pascal_2012_seg/validation'\n",
    "\n",
    "def pair_random_crop(x,y,target_size ,sync_seed=1, **kwargs):\n",
    "    np.random.seed(sync_seed)\n",
    "    # 填充\n",
    "    h, w = x.shape[0], x.shape[1]\n",
    "    pad_w = max(target_size[1] - w, 0)\n",
    "    pad_h = max(target_size[0] - h, 0)\n",
    "    \n",
    "    x = np.lib.pad(x, ((pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2), (0, 0)),\n",
    "                   'constant', constant_values=0.)\n",
    "    y = np.lib.pad(y, ((pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2), (0, 0)),\n",
    "                   'constant', constant_values=0.)\n",
    "\n",
    "    #裁减\n",
    "    h, w = x.shape[0], x.shape[1]\n",
    "    rangeh = (h - target_size[0]) // 2\n",
    "    rangew = (w - target_size[1]) // 2\n",
    "#     print(rangeh,rangew)\n",
    "    offseth = 0 if rangeh == 0 else np.random.randint(rangeh)\n",
    "    offsetw = 0 if rangew == 0 else np.random.randint(rangew)\n",
    "\n",
    "    h_start, h_end = offseth, offseth + target_size[0]\n",
    "    w_start, w_end = offsetw, offsetw + target_size[1]\n",
    "\n",
    "    return x[h_start:h_end, w_start:w_end, :], y[h_start:h_end, w_start:w_end, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "总共有2913张图片，训练集为2621,验证集为292\n",
      "总共有2913张图片，训练集为2621,验证集为292\n",
      "131/131 [==============================] - 107s 816ms/step - loss: 1.2962 - acc: 0.7039 - val_loss: 0.9437 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74736, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 2/40\n",
      "131/131 [==============================] - 100s 767ms/step - loss: 0.9460 - acc: 0.7505 - val_loss: 0.7174 - val_acc: 0.7933\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74736 to 0.79327, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 3/40\n",
      "131/131 [==============================] - 102s 775ms/step - loss: 0.7916 - acc: 0.7794 - val_loss: 0.6029 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.79327 to 0.81469, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 4/40\n",
      "131/131 [==============================] - 107s 819ms/step - loss: 0.6912 - acc: 0.7998 - val_loss: 0.5110 - val_acc: 0.8402\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.81469 to 0.84022, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 5/40\n",
      "131/131 [==============================] - 101s 768ms/step - loss: 0.6154 - acc: 0.8161 - val_loss: 0.4470 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.84022 to 0.85740, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 6/40\n",
      "131/131 [==============================] - 106s 811ms/step - loss: 0.5584 - acc: 0.8295 - val_loss: 0.4066 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85740 to 0.86952, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 7/40\n",
      "131/131 [==============================] - 99s 756ms/step - loss: 0.5142 - acc: 0.8403 - val_loss: 0.3758 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.86952 to 0.87757, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 8/40\n",
      "131/131 [==============================] - 100s 765ms/step - loss: 0.4731 - acc: 0.8510 - val_loss: 0.3494 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.87757 to 0.88563, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 9/40\n",
      "131/131 [==============================] - 101s 770ms/step - loss: 0.4402 - acc: 0.8598 - val_loss: 0.3236 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.88563 to 0.89276, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 10/40\n",
      "131/131 [==============================] - 100s 764ms/step - loss: 0.4121 - acc: 0.8676 - val_loss: 0.3140 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.89276 to 0.89538, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 11/40\n",
      "131/131 [==============================] - 105s 801ms/step - loss: 0.3831 - acc: 0.8758 - val_loss: 0.2944 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.89538 to 0.90135, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 12/40\n",
      "131/131 [==============================] - 97s 740ms/step - loss: 0.3595 - acc: 0.8825 - val_loss: 0.2965 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.90135 to 0.90247, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 13/40\n",
      "131/131 [==============================] - 100s 763ms/step - loss: 0.3386 - acc: 0.8885 - val_loss: 0.2687 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.90247 to 0.90946, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 14/40\n",
      "131/131 [==============================] - 100s 764ms/step - loss: 0.3186 - acc: 0.8945 - val_loss: 0.2558 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.90946 to 0.91446, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 15/40\n",
      "131/131 [==============================] - 101s 769ms/step - loss: 0.3074 - acc: 0.8978 - val_loss: 0.2474 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.91446 to 0.91698, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 16/40\n",
      "131/131 [==============================] - 99s 753ms/step - loss: 0.2883 - acc: 0.9033 - val_loss: 0.2498 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.91698\n",
      "Epoch 17/40\n",
      "131/131 [==============================] - 102s 782ms/step - loss: 0.2783 - acc: 0.9056 - val_loss: 0.2419 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.91698 to 0.91842, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 18/40\n",
      "131/131 [==============================] - 100s 762ms/step - loss: 0.2669 - acc: 0.9096 - val_loss: 0.2458 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.91842 to 0.91875, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 19/40\n",
      "131/131 [==============================] - 100s 763ms/step - loss: 0.2542 - acc: 0.9126 - val_loss: 0.2183 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.91875 to 0.92597, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 20/40\n",
      "131/131 [==============================] - 100s 765ms/step - loss: 0.2452 - acc: 0.9157 - val_loss: 0.2169 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.92597 to 0.92707, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 21/40\n",
      "131/131 [==============================] - 102s 778ms/step - loss: 0.2358 - acc: 0.9183 - val_loss: 0.2265 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92707\n",
      "Epoch 22/40\n",
      "131/131 [==============================] - 107s 818ms/step - loss: 0.2303 - acc: 0.9196 - val_loss: 0.2113 - val_acc: 0.9303\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.92707 to 0.93034, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 23/40\n",
      "131/131 [==============================] - 108s 826ms/step - loss: 0.2201 - acc: 0.9227 - val_loss: 0.1946 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.93034 to 0.93240, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 24/40\n",
      "131/131 [==============================] - 100s 762ms/step - loss: 0.2145 - acc: 0.9243 - val_loss: 0.2167 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93240\n",
      "Epoch 25/40\n",
      "131/131 [==============================] - 99s 758ms/step - loss: 0.2072 - acc: 0.9263 - val_loss: 0.1929 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.93240 to 0.93444, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 26/40\n",
      "131/131 [==============================] - 100s 763ms/step - loss: 0.2020 - acc: 0.9282 - val_loss: 0.2017 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.93444\n",
      "Epoch 27/40\n",
      "131/131 [==============================] - 105s 800ms/step - loss: 0.1981 - acc: 0.9292 - val_loss: 0.1886 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.93444 to 0.93596, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 28/40\n",
      "131/131 [==============================] - 97s 741ms/step - loss: 0.1927 - acc: 0.9307 - val_loss: 0.1883 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.93596\n",
      "Epoch 29/40\n",
      "131/131 [==============================] - 101s 774ms/step - loss: 0.1888 - acc: 0.9321 - val_loss: 0.1904 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.93596 to 0.93757, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 30/40\n",
      "131/131 [==============================] - 100s 762ms/step - loss: 0.1838 - acc: 0.9331 - val_loss: 0.1948 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93757\n",
      "Epoch 31/40\n",
      "131/131 [==============================] - 99s 756ms/step - loss: 0.1811 - acc: 0.9340 - val_loss: 0.1869 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.93757\n",
      "Epoch 32/40\n",
      "131/131 [==============================] - 97s 741ms/step - loss: 0.1779 - acc: 0.9350 - val_loss: 0.1838 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.93757 to 0.93856, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 33/40\n",
      "131/131 [==============================] - 102s 776ms/step - loss: 0.1731 - acc: 0.9361 - val_loss: 0.1851 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.93856 to 0.93901, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 34/40\n",
      "131/131 [==============================] - 101s 773ms/step - loss: 0.1706 - acc: 0.9370 - val_loss: 0.1881 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.93901\n",
      "Epoch 35/40\n",
      "131/131 [==============================] - 99s 754ms/step - loss: 0.1686 - acc: 0.9376 - val_loss: 0.1761 - val_acc: 0.9398\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.93901 to 0.93980, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 36/40\n",
      "131/131 [==============================] - 98s 745ms/step - loss: 0.1644 - acc: 0.9386 - val_loss: 0.1727 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.93980 to 0.94193, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 37/40\n",
      "131/131 [==============================] - 97s 740ms/step - loss: 0.1629 - acc: 0.9392 - val_loss: 0.1731 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.94193 to 0.94201, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 38/40\n",
      "131/131 [==============================] - 102s 782ms/step - loss: 0.1589 - acc: 0.9405 - val_loss: 0.1756 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.94201\n",
      "Epoch 39/40\n",
      "131/131 [==============================] - 100s 767ms/step - loss: 0.1579 - acc: 0.9407 - val_loss: 0.1684 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.94201 to 0.94368, saving model to ./models/lab_01_fcn32s.hdf5\n",
      "Epoch 40/40\n",
      "131/131 [==============================] - 100s 763ms/step - loss: 0.1569 - acc: 0.9410 - val_loss: 0.1846 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.94368\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "import random,csv\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "checkpoint=ModelCheckpoint('./models/lab_01_fcn32s.hdf5',monitor='val_acc',save_best_only=True,verbose=1)\n",
    "tensorboard=TensorBoard(log_dir='./tf_dir', histogram_freq=0, batch_size=20)\n",
    "if not os.path.exists('./models'):\n",
    "    os.mkdir('./models')\n",
    "if not os.path.exists('./tf_dir'):\n",
    "    os.mkdir('./tf_dir')\n",
    "\n",
    "def train_val_generator(root_dir,batch_size,num_classes,train=True,target_size=(320,320)):\n",
    "    all_list=[]\n",
    "    with open('%s/meta.csv'%root_dir) as fr:\n",
    "        f_csv=csv.reader(fr)\n",
    "        next(f_csv)\n",
    "        for each in f_csv:\n",
    "            all_list.append(each)\n",
    "    random.shuffle(all_list)\n",
    "    train_num=int(len(all_list)*0.9)\n",
    "    batch=0\n",
    "    img_batch=[]\n",
    "    mask_batch=[]\n",
    "    print('总共有%d张图片，训练集为%d,验证集为%d'%(len(all_list),train_num,len(all_list)-train_num))\n",
    "    if train:\n",
    "        all_list=all_list[:train_num]\n",
    "    else:\n",
    "        all_list=all_list[train_num:]\n",
    "    while True:\n",
    "        for i in range(len(all_list)):\n",
    "            batch+=1\n",
    "            img=io.imread(os.path.join(root_dir,all_list[i][1]))\n",
    "#             print(img)\n",
    "            img=img.astype('float32')\n",
    "            img/=255.\n",
    "            mask=io.imread(os.path.join(root_dir,all_list[i][0]))\n",
    "            img,mask=pair_random_crop(img,mask,target_size)\n",
    "            img_batch.append(img)\n",
    "            mask_batch.append(mask)\n",
    "            if batch%batch_size==0:\n",
    "                #将一个batch的mask从rgb->单通道—>one-hot形式\n",
    "                img_batch,mask_batch=np.array(img_batch),np.array(mask_batch)\n",
    "                mask_one_hot=np.zeros(mask_batch[:,:,:,0].shape+(num_classes,))\n",
    "                mask_idx=np.zeros(mask_batch[:,:,:,0].shape)\n",
    "                for j in range(batch_size):\n",
    "                    mask_idx[j]=image2label(mask_batch[j])\n",
    "                    \n",
    "                for z in range(num_classes):\n",
    "                    mask_one_hot[mask_idx==z,z]=1\n",
    "                mask_one_hot=mask_one_hot.astype('int32')\n",
    "                yield img_batch,mask_one_hot\n",
    "                batch=0\n",
    "                img_batch=[]\n",
    "                mask_batch=[]\n",
    "                \n",
    "            \n",
    "            \n",
    "root_dir='/input1/Pascal_Voc_2012_Segmentation'\n",
    "history=model.fit_generator(train_val_generator(root_dir,batch_size=20,num_classes=21),steps_per_epoch=131,\n",
    "                            epochs=40,validation_data=train_val_generator(root_dir,batch_size=20,num_classes=21,train=False),\n",
    "                            validation_steps=15,\n",
    "                            callbacks=[checkpoint,tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
